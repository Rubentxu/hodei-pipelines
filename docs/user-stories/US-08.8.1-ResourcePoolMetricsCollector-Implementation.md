# User Story US-08.8.1: ResourcePoolMetricsCollector Implementation

## üìã Story Information

- **Story ID**: US-08.8.1
- **Epic**: EPIC-08 - Resource Pool Architecture Implementation
- **Sub-EPIC**: 08.8 - Monitoring & Observability
- **Priority**: Medium
- **Estimated Effort**: 3 days
- **Dependencies**: US-08.7.1 (MultiTenancyQuotaManager Implementation)
- **Assigned To**: Core Platform Team

---

## üéØ Story Description

As a **Site Reliability Engineer**, I want to **collect and export comprehensive metrics for all resource pools** so that **we can monitor system health, optimize performance, detect anomalies, and make data-driven scaling decisions**.

---

## üìñ Context

Metrics collection is critical for:

1. **System monitoring**: Track pool health and performance
2. **Auto-scaling**: Provide data for scaling policies
3. **Troubleshooting**: Debug issues with historical data
4. **Capacity planning**: Predict future resource needs
5. **Cost optimization**: Identify inefficiencies
6. **SLA monitoring**: Verify performance guarantees

---

## ‚úÖ Acceptance Criteria

### AC-1: Core Pool Metrics
- [ ] Pool size: current, min, max workers
- [ ] Worker states: available, busy, idle, provisioning, terminating
- [ ] Job metrics: queued, running, completed, failed, cancelled
- [ ] Queue metrics: length, wait time, abandonment rate
- [ ] Resource utilization: CPU, memory, network

### AC-2: Performance Metrics
- [ ] Allocation latency: time from request to worker assignment
- [ ] Provisioning time: worker creation duration
- [ ] Termination time: worker cleanup duration
- [ ] Job execution time: end-to-end job runtime
- [ ] Throughput: jobs/minute, workers/sec

### AC-3: Health & Reliability Metrics
- [ ] Worker health: healthy, unhealthy, unknown workers
- [ ] Provisioning success rate: % successful provisions
- [ ] Termination success rate: % successful terminations
- [ ] Error rates: by error type
- [ ] MTTR: mean time to recovery from failures

### AC-4: Cost & Efficiency Metrics
- [ ] Cost per job: actual cost
- [ ] Resource utilization efficiency: % resources used
- [ ] Idle time: worker idle duration distribution
- [ ] Scaling efficiency: ratio of scaling actions to actual need
- [ ] Wastage: resources provisioned but never used

### AC-5: Multi-Tenant Metrics
- [ ] Per-tenant resource usage
- [ ] Quota utilization per tenant
- [ ] Fair share distribution
- [ ] Tenant cost breakdown
- [ ] Cross-tenant impact analysis

### AC-6: Metrics Export
- [ ] Prometheus metrics (pull model)
- [ ] OpenTelemetry traces
- [ ] JSON metrics API (push model)
- [ ] Metrics aggregation (1m, 5m, 1h intervals)
- [ ] Long-term storage integration

---

## üõ†Ô∏è Implementation Details

```rust
/// Metrics collector for resource pools
#[derive(Debug)]
pub struct ResourcePoolMetricsCollector {
    pools: Arc<RwLock<HashMap<PoolId, Box<dyn ResourcePool>>>>,
    metrics_store: Arc<MetricsStore>,
    prometheus_registry: Registry,
    collection_interval: Duration,
}

/// Metrics types
#[derive(Debug, Clone)]
pub struct PoolMetrics {
    pub pool_id: PoolId,
    pub timestamp: Instant,
    pub pool_size: PoolSizeMetrics,
    pub worker_states: WorkerStateMetrics,
    pub job_metrics: JobMetrics,
    pub performance: PerformanceMetrics,
    pub health: HealthMetrics,
    pub cost: CostMetrics,
}

#[derive(Debug, Clone)]
pub struct PoolSizeMetrics {
    pub current_size: u32,
    pub min_size: u32,
    pub max_size: u32,
    pub target_size: u32,
}

#[derive(Debug, Clone)]
pub struct WorkerStateMetrics {
    pub available: u32,
    pub busy: u32,
    pub idle: u32,
    pub provisioning: u32,
    pub terminating: u32,
    pub unhealthy: u32,
}

/// Metrics collection implementation
impl ResourcePoolMetricsCollector {
    pub fn start_collection(&self) {
        let interval = self.collection_interval;
        let pools = self.pools.clone();
        let metrics_store = self.metrics_store.clone();

        tokio::spawn(async move {
            let mut interval_timer = tokio::time::interval(interval);

            loop {
                interval_timer.tick().await;

                for (pool_id, pool) in pools.read().await.iter() {
                    match Self::collect_pool_metrics(pool_id, pool).await {
                        Ok(metrics) => {
                            metrics_store.store_metrics(&metrics).await;
                        }
                        Err(e) => {
                            tracing::error!(pool_id = %pool_id, error = %e, "Failed to collect metrics");
                        }
                    }
                }
            }
        });
    }

    async fn collect_pool_metrics(pool_id: &PoolId, pool: &Box<dyn ResourcePool>) -> Result<PoolMetrics, MetricsError> {
        let status = pool.status().await?;

        Ok(PoolMetrics {
            pool_id: pool_id.clone(),
            timestamp: Instant::now(),
            pool_size: PoolSizeMetrics {
                current_size: status.total_workers,
                min_size: status.min_workers,
                max_size: status.max_workers,
                target_size: status.target_workers,
            },
            worker_states: WorkerStateMetrics {
                available: status.available_workers,
                busy: status.busy_workers,
                idle: status.idle_workers,
                provisioning: status.provisioning_workers,
                terminating: status.terminating_workers,
                unhealthy: status.unhealthy_workers,
            },
            job_metrics: JobMetrics {
                queued: status.queued_jobs,
                running: status.running_jobs,
                completed: status.completed_jobs,
                failed: status.failed_jobs,
            },
            performance: PerformanceMetrics {
                allocation_latency_p50: status.allocation_latency.p50,
                allocation_latency_p95: status.allocation_latency.p95,
                allocation_latency_p99: status.allocation_latency.p99,
                provisioning_time_p50: status.provisioning_time.p50,
                throughput_jobs_per_min: status.throughput.jobs_per_min,
            },
            health: HealthMetrics {
                provisioning_success_rate: status.provisioning_success_rate,
                termination_success_rate: status.termination_success_rate,
                error_rate: status.error_rate,
                mttr_minutes: status.mttr.as_minutes(),
            },
            cost: CostMetrics {
                cost_per_job: status.cost_per_job,
                resource_utilization: status.resource_utilization,
                idle_time_avg: status.idle_time_avg,
                wastage_percentage: status.wastage_percentage,
            },
        })
    }
}

/// Prometheus metrics exporter
#[derive(Debug)]
pub struct PrometheusMetricsExporter {
    pool_size_gauge: GaugeVec,
    worker_state_gauge: GaugeVec,
    job_counter: CounterVec,
    latency_histogram: HistogramVec,
    success_rate_gauge: GaugeVec,
}
```

---

## üìä Success Metrics

- Metrics collection coverage: 100% (all pools and workers)
- Collection latency: < 5 seconds (real-time monitoring)
- Metrics accuracy: > 99.9%
- Storage efficiency: < 1GB/day for 100 pools
- Alert responsiveness: < 30 seconds from metric threshold breach

---

**Story Status**: üìã Draft
**Created**: 2025-11-24
