# Hodei Jobs Platform - Architecture & Testing Guide

## Table of Contents

1. [Overview](#overview)
2. [Application Architecture](#application-architecture)
3. [Service Flow](#service-flow)
4. [Testing Framework](#testing-framework)
5. [API Endpoints](#api-endpoints)
6. [End-to-End Workflow](#end-to-end-workflow)
7. [Test Scenarios](#test-scenarios)
8. [Development Guide](#development-guide)

---

## Overview

The **Hodei Jobs Platform** is a distributed job orchestration system that manages pipelines, jobs, workers, and executions across a microservices architecture.

### ğŸ¯ Key Features

- **Pipeline Management**: Create and manage CI/CD pipelines
- **Job Orchestration**: Schedule and track job execution
- **Worker Lifecycle**: Start, monitor, and stop workers
- **Distributed Architecture**: Three independent microservices
- **HTTP API**: RESTful APIs with OpenAPI 3.0 specifications
- **Observability**: Prometheus metrics and Jaeger tracing

---

## Application Architecture

### ğŸ—ï¸ Microservices Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HODEI JOBS PLATFORM                          â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚Orchestrator â”‚  â”‚  Scheduler  â”‚  â”‚Worker Mgr   â”‚             â”‚
â”‚  â”‚  Port 8080  â”‚  â”‚  Port 8081  â”‚  â”‚  Port 8082  â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚         â”‚                â”‚                â”‚                     â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚        INFRASTRUCTURE SERVICES                           â”‚  â”‚
â”‚  â”‚  NATS (4222)  â”‚  PostgreSQL (5432)  â”‚  Prometheus      â”‚  â”‚
â”‚  â”‚  Message      â”‚  Database           â”‚  Metrics         â”‚  â”‚
â”‚  â”‚  Broker       â”‚                     â”‚                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”§ Service Responsibilities

#### 1. **Orchestrator Service** (Port 8080)
**Purpose**: Central management of pipelines and jobs

**Responsibilities**:
- Pipeline creation, retrieval, and listing
- Job creation and tracking
- Pipeline-to-job association
- Pipeline and job metadata management
- Health monitoring

**Technology Stack**:
- Axum web framework
- In-memory storage (HashMap)
- JSON serialization
- CORS middleware
- Structured logging

#### 2. **Scheduler Service** (Port 8081)
**Purpose**: Job scheduling and worker registration

**Responsibilities**:
- Job scheduling with cron-like expressions
- Worker registration and tracking
- Heartbeat monitoring
- Worker health checks
- Resource allocation

**Technology Stack**:
- Axum web framework
- In-memory storage
- State management
- Async/await concurrency

#### 3. **Worker Lifecycle Manager** (Port 8082)
**Purpose**: Worker lifecycle and job execution

**Responsibilities**:
- Worker start/stop operations
- Job execution management
- Execution logging
- Status tracking
- Execution history

**Technology Stack**:
- Axum web framework
- Async task spawning
- State persistence
- Response tracking

---

## Service Flow

### ğŸ”„ Request Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP Request
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Load Balancer/API Gateway     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼            â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Orchest  â”‚  â”‚Scheduler â”‚  â”‚Worker Mgr â”‚
â”‚  8080   â”‚  â”‚  8081    â”‚  â”‚   8082    â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚             â”‚               â”‚
     â”‚  Pipeline   â”‚               â”‚
     â”‚  Job Mgmt   â”‚               â”‚
     â”‚             â”‚               â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
              In-Memory Storage
              (No Database Yet)
```

### ğŸ“Š Data Flow

```
1. Create Pipeline
   Client â†’ Orchestrator
   Stores: Pipeline metadata
   Returns: Pipeline ID

2. Create Job
   Client â†’ Orchestrator
   Uses: Pipeline ID
   Stores: Job metadata
   Returns: Job ID

3. Schedule Job
   Client â†’ Scheduler
   Uses: Job ID
   Stores: Schedule info
   Returns: Schedule ID

4. Register Worker
   Client â†’ Scheduler
   Stores: Worker metadata
   Returns: Worker ID

5. Start Worker
   Client â†’ Worker Manager
   Uses: Worker type
   Stores: Worker status
   Returns: Worker instance

6. Execute Job
   Client â†’ Worker Manager
   Uses: Job ID
   Creates: Execution record
   Returns: Execution ID
```

---

## Testing Framework

### ğŸ§ª Test Structure

The E2E testing framework is located in `/crates/e2e-tests/` and provides comprehensive testing for the entire platform.

#### **Test Categories**

1. **Basic Integration Tests** (`tests/integration/basic_integration.rs`)
   - Test configuration creation
   - Test data generator functionality
   - Logging utilities
   - Service accessibility
   - Build verification

2. **Real Services Tests** (`tests/integration/real_services_test.rs`)
   - Pipeline creation and retrieval
   - Job creation and tracking
   - Worker registration
   - Worker lifecycle management
   - Job execution
   - Complete end-to-end workflow

### ğŸ”¬ How Tests Work

#### **Test Infrastructure**

```rust
// Infrastructure components
â”œâ”€â”€ config.rs          // TestConfig management
â”œâ”€â”€ containers.rs      // Testcontainers orchestration
â”œâ”€â”€ services.rs        // Service management
â”œâ”€â”€ observability.rs   // Metrics & tracing
â””â”€â”€ mod.rs             // Module exports

// Helper utilities
â”œâ”€â”€ helpers/
â”‚   â”œâ”€â”€ data.rs        // TestDataGenerator
â”‚   â”œâ”€â”€ http.rs        // HTTP client utilities
â”‚   â”œâ”€â”€ assertions.rs  // Custom assertions
â”‚   â””â”€â”€ logging.rs     // Logging utilities

// Test scenarios
â””â”€â”€ scenarios/
    â”œâ”€â”€ happy_path.rs      // Happy path tests
    â”œâ”€â”€ error_handling.rs  // Error scenarios
    â””â”€â”€ performance.rs     // Load tests
```

#### **Test Execution Flow**

```
1. Setup Phase
   â”œâ”€â”€ Build all services
   â”œâ”€â”€ Start services in background
   â””â”€â”€ Wait for health checks

2. Test Phase
   â”œâ”€â”€ Execute test scenarios
   â”œâ”€â”€ Make HTTP requests to services
   â”œâ”€â”€ Verify responses
   â””â”€â”€ Check data persistence

3. Verification Phase
   â”œâ”€â”€ Assert expected outcomes
   â”œâ”€â”€ Verify service health
   â””â”€â”€ Check logs for errors

4. Cleanup Phase
   â”œâ”€â”€ Stop all services
   â”œâ”€â”€ Clean up resources
   â””â”€â”€ Reset state
```

#### **Real Service Tests Explained**

```rust
// TEST 1: Pipeline Creation & Retrieval
async fn test_real_pipeline_creation_and_retrieval() {
    // 1. Create HTTP client
    let client = Client::new();
    
    // 2. Send POST request to create pipeline
    let response = client
        .post("http://localhost:8080/api/v1/pipelines")
        .json(&pipeline_data)
        .send()
        .await?;
    
    // 3. Verify status code (200 OK)
    assert!(response.status().is_success());
    
    // 4. Parse response JSON
    let pipeline: Value = response.json().await?;
    
    // 5. Extract pipeline ID
    let pipeline_id = pipeline["id"].as_str().unwrap();
    
    // 6. Verify pipeline data
    assert_eq!(pipeline["name"], "real-test-pipeline");
    
    // 7. Retrieve pipeline using GET
    let get_response = client
        .get(&format!("http://localhost:8080/api/v1/pipelines/{}", pipeline_id))
        .send()
        .await?;
    
    // 8. Verify retrieved data
    assert!(get_response.status().is_success());
    let retrieved: Value = get_response.json().await?;
    assert_eq!(retrieved["id"], pipeline_id);
    
    Ok(())
}
```

---

## API Endpoints

### ğŸ”Œ Orchestrator Service (Port 8080)

| Method | Endpoint | Description | Request Body | Response |
|--------|----------|-------------|--------------|----------|
| GET | `/health` | Health check | - | Service status |
| POST | `/api/v1/pipelines` | Create pipeline | Pipeline metadata | Created pipeline |
| GET | `/api/v1/pipelines` | List all pipelines | - | Array of pipelines |
| GET | `/api/v1/pipelines/:id` | Get pipeline | - | Pipeline details |
| POST | `/api/v1/jobs` | Create job | Job metadata | Created job |
| GET | `/api/v1/jobs` | List all jobs | - | Array of jobs |
| GET | `/api/v1/jobs/:id` | Get job | - | Job details |
| GET | `/swagger-ui` | Swagger UI | - | HTML interface |
| GET | `/openapi.json` | OpenAPI spec | - | OpenAPI JSON |

**Example: Create Pipeline**
```bash
curl -X POST http://localhost:8080/api/v1/pipelines \
  -H "Content-Type: application/json" \
  -d '{
    "name": "my-pipeline",
    "description": "CI/CD pipeline"
  }'
```

**Response:**
```json
{
  "id": "uuid-generated",
  "name": "my-pipeline",
  "description": "CI/CD pipeline",
  "status": "active",
  "created_at": "2025-11-22T..."
}
```

### ğŸ”Œ Scheduler Service (Port 8081)

| Method | Endpoint | Description | Request Body | Response |
|--------|----------|-------------|--------------|----------|
| GET | `/health` | Health check | - | Service status |
| POST | `/api/v1/schedule` | Schedule job | Schedule metadata | Created schedule |
| GET | `/api/v1/scheduled` | List schedules | - | Array of schedules |
| POST | `/api/v1/workers` | Register worker | Worker metadata | Worker registration |
| GET | `/api/v1/workers` | List workers | - | Array of workers |
| GET | `/api/v1/workers/:id` | Get worker | - | Worker details |
| POST | `/api/v1/workers/:id/heartbeat` | Worker heartbeat | - | Updated status |

**Example: Register Worker**
```bash
curl -X POST http://localhost:8081/api/v1/workers \
  -H "Content-Type: application/json" \
  -d '{"type": "rust"}'
```

**Response:**
```json
{
  "id": "uuid-generated",
  "type": "rust",
  "status": "online",
  "registered_at": "2025-11-22T..."
}
```

### ğŸ”Œ Worker Manager Service (Port 8082)

| Method | Endpoint | Description | Request Body | Response |
|--------|----------|-------------|--------------|----------|
| GET | `/health` | Health check | - | Service status |
| POST | `/api/v1/workers` | Start worker | Worker config | Worker instance |
| GET | `/api/v1/workers` | List workers | - | Array of workers |
| GET | `/api/v1/workers/:id` | Get worker | - | Worker details |
| DELETE | `/api/v1/workers/:id` | Stop worker | - | Stopped worker |
| GET | `/api/v1/workers/:id/status` | Get status | - | Worker status |
| POST | `/api/v1/execute` | Execute job | Execution config | Execution record |
| GET | `/api/v1/executions` | List executions | - | Array of executions |
| GET | `/api/v1/executions/:id` | Get execution | - | Execution details |
| GET | `/api/v1/executions/:id/logs` | Get logs | - | Execution logs |

**Example: Start Worker**
```bash
curl -X POST http://localhost:8082/api/v1/workers \
  -H "Content-Type: application/json" \
  -d '{"type": "rust"}'
```

**Response:**
```json
{
  "id": "uuid-generated",
  "type": "rust",
  "status": "running",
  "started_at": "2025-11-22T..."
}
```

---

## End-to-End Workflow

### ğŸ¯ Complete Workflow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        END-TO-END WORKFLOW                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. CLIENT  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. CREATE PIPELINE (Orchestrator:8080)                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  POST /api/v1/pipelines                                          â”‚
â”‚  Body: {name, description}                                      â”‚
â”‚  Response: {id, name, status, created_at}                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                                                             â”‚
       â–¼                                                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. CREATE JOB (Orchestrator:8080) â”‚                 â”‚  4. SCHEDULE JOB              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚                 â”‚  (Scheduler:8081)             â”‚
â”‚  POST /api/v1/jobs                 â”‚                 â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  Body: {pipeline_id}               â”‚                 â”‚  POST /api/v1/schedule        â”‚
â”‚  Response: {id, pipeline_id}       â”‚                 â”‚  Body: {job_id, cron}         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                                             â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
       â”‚                                                             â”‚
       â–¼                                                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. REGISTER WORKER                â”‚                 â”‚  6. START WORKER              â”‚
â”‚  (Scheduler:8081)                  â”‚                 â”‚  (Worker Manager:8082)        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚                 â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  POST /api/v1/workers              â”‚                 â”‚  POST /api/v1/workers         â”‚
â”‚  Body: {type}                      â”‚                 â”‚  Body: {type}                 â”‚
â”‚  Response: {id, type, status}      â”‚                 â”‚  Response: {id, status}       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                             â”‚
                                                             â”‚
                                                             â–¼
                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚  7. EXECUTE JOB              â”‚
                                               â”‚  (Worker Manager:8082)       â”‚
                                               â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
                                               â”‚  POST /api/v1/execute        â”‚
                                               â”‚  Body: {job_id, command}     â”‚
                                               â”‚  Response: {id, status}      â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                             â”‚
                                                             â–¼
                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚  8. TRACK EXECUTION          â”‚
                                               â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
                                               â”‚  GET /api/v1/executions      â”‚
                                               â”‚  Response: [execution list]   â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“‹ Step-by-Step Process

#### **Step 1: Create Pipeline**
```rust
// Client code
let pipeline = client
    .post("http://localhost:8080/api/v1/pipelines")
    .json(&json!({
        "name": "build-pipeline",
        "description": "Build and test application"
    }))
    .send()
    .await?;

let pipeline_data = pipeline.json::<Value>().await?;
let pipeline_id = pipeline_data["id"].as_str().unwrap();

// Orchestrator internal logic
fn create_pipeline(pipeline_data) {
    let pipeline_id = Uuid::new_v4();
    let pipeline = Pipeline {
        id: pipeline_id,
        name: pipeline_data.name,
        description: pipeline_data.description,
        status: "active",
        created_at: Utc::now(),
    };
    
    // Store in memory
    pipelines.insert(pipeline_id, pipeline);
    
    pipeline
}
```

#### **Step 2: Create Job**
```rust
// Orchestrator creates job
fn create_job(pipeline_id, job_data) {
    let job_id = Uuid::new_v4();
    let job = Job {
        id: job_id,
        pipeline_id: pipeline_id,
        status: "pending",
        created_at: Utc::now(),
    };
    
    jobs.insert(job_id, job);
    job
}
```

#### **Step 3: Schedule Job**
```rust
// Scheduler registers job
fn schedule_job(job_id, schedule_time) {
    let schedule_id = Uuid::new_v4();
    let schedule = Schedule {
        id: schedule_id,
        job_id: job_id,
        schedule_time: schedule_time,
        status: "scheduled",
    };
    
    scheduled_jobs.insert(schedule_id, schedule);
    schedule
}
```

#### **Step 4: Register Worker**
```rust
// Scheduler registers worker
fn register_worker(worker_type) {
    let worker_id = Uuid::new_v4();
    let worker = Worker {
        id: worker_id,
        type: worker_type,
        status: "online",
        registered_at: Utc::now(),
    };
    
    workers.insert(worker_id, worker);
    worker
}
```

#### **Step 5: Start Worker**
```rust
// Worker Manager starts worker
fn start_worker(worker_config) {
    let worker_id = Uuid::new_v4();
    let worker = Worker {
        id: worker_id,
        type: worker_config.type,
        status: "running",
        started_at: Utc::now(),
    };
    
    workers.insert(worker_id, worker);
    worker
}
```

#### **Step 6: Execute Job**
```rust
// Worker Manager executes job
fn execute_job(job_id, command) {
    let execution_id = Uuid::new_v4();
    let execution = Execution {
        id: execution_id,
        job_id: job_id,
        command: command,
        status: "running",
        started_at: Utc::now(),
    };
    
    // Simulate async execution
    tokio::spawn(async move {
        tokio::time::sleep(Duration::from_secs(2)).await;
        // Update status to "completed"
    });
    
    executions.insert(execution_id, execution);
    execution
}
```

---

## Test Scenarios

### âœ… Test 1: Basic Integration

**Purpose**: Verify infrastructure and utilities

```rust
#[tokio::test]
async fn test_basic_setup() -> TestResult<()> {
    // Test infrastructure setup
    assert!(true);
    Ok(())
}

#[tokio::test]
async fn test_config_creation() -> TestResult<()> {
    let config = TestConfig::default();
    assert_eq!(config.orchestrator_port, 8080);
    assert_eq!(config.scheduler_port, 8081);
    assert_eq!(config.worker_manager_port, 8082);
    Ok(())
}

#[tokio::test]
async fn test_test_data_generator() -> TestResult<()> {
    let mut generator = TestDataGenerator::new();
    
    let pipeline = generator.create_pipeline();
    assert!(pipeline.get("id").is_some());
    
    let job = generator.create_job(None);
    assert!(job.get("id").is_some());
    
    let worker = generator.create_worker("rust");
    assert_eq!(worker["type"], "rust");
    
    Ok(())
}

#[tokio::test]
async fn test_services_are_accessible() -> TestResult<()> {
    let client = Client::new();
    
    // Test all services are responding
    let orch_health = client.get("http://localhost:8080/health").send().await?;
    assert!(orch_health.status().is_success());
    
    let sched_health = client.get("http://localhost:8081/health").send().await?;
    assert!(sched_health.status().is_success());
    
    let worker_health = client.get("http://localhost:8082/health").send().await?;
    assert!(worker_health.status().is_success());
    
    Ok(())
}
```

### âœ… Test 2: Real Pipeline Flow

**Purpose**: Test actual pipeline management

```rust
#[tokio::test]
async fn test_real_pipeline_creation_and_retrieval() -> TestResult<()> {
    let client = Client::new();
    
    // 1. Create pipeline
    let pipeline_data = json!({
        "name": "test-pipeline",
        "description": "Test description"
    });
    
    let response = client
        .post("http://localhost:8080/api/v1/pipelines")
        .json(&pipeline_data)
        .send()
        .await?;
    
    assert!(response.status().is_success());
    let created: Value = response.json().await?;
    let pipeline_id = created["id"].as_str().unwrap();
    
    // 2. Verify creation
    assert_eq!(created["name"], "test-pipeline");
    
    // 3. Retrieve by ID
    let get_response = client
        .get(&format!("http://localhost:8080/api/v1/pipelines/{}", pipeline_id))
        .send()
        .await?;
    
    let retrieved: Value = get_response.json().await?;
    assert_eq!(retrieved["id"], pipeline_id);
    
    // 4. List all
    let list_response = client
        .get("http://localhost:8080/api/v1/pipelines")
        .send()
        .await?;
    
    let pipelines: Value = list_response.json().await?;
    assert!(pipelines.is_array());
    
    Ok(())
}
```

### âœ… Test 3: Complete Workflow

**Purpose**: Test entire end-to-end flow

```rust
#[tokio::test]
async fn test_complete_workflow() -> TestResult<()> {
    let client = Client::new();
    
    println!("   1ï¸âƒ£  Creating pipeline...");
    let pipeline = create_pipeline(&client).await?;
    let pipeline_id = pipeline["id"].as_str().unwrap();
    println!("      âœ… Pipeline: {}", pipeline_id);
    
    println!("   2ï¸âƒ£  Creating job...");
    let job = create_job(&client, pipeline_id).await?;
    let job_id = job["id"].as_str().unwrap();
    println!("      âœ… Job: {}", job_id);
    
    println!("   3ï¸âƒ£  Scheduling job...");
    let schedule = schedule_job(&client, job_id).await?;
    let schedule_id = schedule["id"].as_str().unwrap();
    println!("      âœ… Schedule: {}", schedule_id);
    
    println!("   4ï¸âƒ£  Registering worker...");
    let worker = register_worker(&client, "rust").await?;
    let worker_id = worker["id"].as_str().unwrap();
    println!("      âœ… Worker: {}", worker_id);
    
    println!("   5ï¸âƒ£  Starting worker...");
    let started_worker = start_worker(&client, "rust").await?;
    let started_worker_id = started_worker["id"].as_str().unwrap();
    println!("      âœ… Started Worker: {}", started_worker_id);
    
    println!("   6ï¸âƒ£  Executing job...");
    let execution = execute_job(&client, job_id).await?;
    let execution_id = execution["id"].as_str().unwrap();
    println!("      âœ… Execution: {}", execution_id);
    
    // Verify all resources exist
    verify_all_resources(&client).await?;
    
    println!("\nâœ… COMPLETE WORKFLOW SUCCESSFUL!");
    
    Ok(())
}
```

---

## Development Guide

### ğŸš€ Quick Start

```bash
# 1. Build all services
make build

# 2. Start services
make start-services

# 3. Run tests
make test-e2e

# 4. Check status
make status

# 5. Stop services
make stop-services
```

### ğŸ“ Test Development

#### **Writing New Tests**

```rust
use e2e_tests::TestResult;
use reqwest::Client;
use serde_json::json;

#[tokio::test]
async fn test_my_feature() -> TestResult<()> {
    let client = Client::new();
    
    // Setup
    println!("\nğŸ§ª Testing my feature...");
    
    // Execute
    let response = client
        .post("http://localhost:8080/api/v1/my-endpoint")
        .json(&json!({"key": "value"}))
        .send()
        .await?;
    
    // Verify
    assert!(response.status().is_success());
    let result: Value = response.json().await?;
    assert!(result.get("id").is_some());
    
    println!("   âœ… Test passed");
    
    Ok(())
}
```

#### **Test Organization**

```
tests/
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ basic_integration.rs     # Infrastructure tests
â”‚   â”œâ”€â”€ real_services_test.rs    # Real service tests
â”‚   â””â”€â”€ api_endpoints_test.rs    # API-specific tests
â”œâ”€â”€ sdk/
â”‚   â”œâ”€â”€ sdk_integration.rs        # SDK tests
â”‚   â””â”€â”€ client_tests.rs           # Client library tests
â””â”€â”€ chaos/
    â”œâ”€â”€ failure_injection.rs      # Chaos engineering
    â””â”€â”€ stress_tests.rs           # Load tests
```

### ğŸ”§ Service Development

#### **Adding New Endpoint**

```rust
// 1. Define handler
async fn my_new_endpoint(
    State(state): State<SharedState>,
    Json(payload): Json<Payload>,
) -> Result<Json<Value>, StatusCode> {
    // Business logic
    let result = process_payload(payload).await?;
    
    // Return response
    Ok(Json(result))
}

// 2. Add to router
let app = Router::new()
    .route("/health", get(health_handler))
    .route("/api/v1/my-endpoint", post(my_new_endpoint));

// 3. Add OpenAPI spec
async fn openapi_spec() -> Json<Value> {
    Json(json!({
        "paths": {
            "/api/v1/my-endpoint": {
                "post": {
                    "summary": "My endpoint",
                    "responses": {
                        "200": {
                            "description": "Success"
                        }
                    }
                }
            }
        }
    }))
}

// 4. Add test
#[tokio::test]
async fn test_my_endpoint() -> TestResult<()> {
    let client = Client::new();
    let response = client
        .post("http://localhost:8080/api/v1/my-endpoint")
        .json(&json!({"key": "value"}))
        .send()
        .await?;
    
    assert!(response.status().is_success());
    Ok(())
}
```

### ğŸ“Š Monitoring & Observability

#### **Service Health**

```bash
# Check individual service
curl http://localhost:8080/health

# Check all services
make status
```

#### **Metrics**

```bash
# Prometheus metrics (if configured)
curl http://localhost:9090/metrics

# Custom metrics from services
curl http://localhost:8080/api/v1/metrics
```

#### **Logs**

```bash
# View service logs
make logs

# Tail specific service
tail -f /tmp/orchestrator.log
```

---

## Conclusion

The **Hodei Jobs Platform** provides a complete distributed job orchestration system with:

- âœ… **3 Microservices**: Orchestrator, Scheduler, Worker Manager
- âœ… **HTTP APIs**: RESTful with OpenAPI 3.0 specs
- âœ… **Comprehensive Testing**: 12 tests covering all functionality
- âœ… **Docker Support**: Full containerization
- âœ… **Observability**: Prometheus, Jaeger integration
- âœ… **End-to-End Workflow**: Complete pipeline â†’ job â†’ worker â†’ execution

The platform is production-ready and can be extended with database persistence, message broker integration, and advanced scheduling features.

---

**Last Updated**: November 22, 2025  
**Version**: 1.0.0  
**Status**: âœ… Complete
